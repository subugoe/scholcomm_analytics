---
title: "Presenting a method for improving the classification of research content in OpenAlex"
description: Although OpenAlex has revised its document types in the past, there is still room for improvement. In this blog post, I introduce a document type classifier that reduces the number of research content that is incorrectly classified as articles or reviews in OpenAlex. 
author:
  - name: Nick Haupka 
    affiliation: State and University Library GÃ¶ttingen
    affiliation_url: https://www.sub.uni-goettingen.de/
    orcid_id: 0009-0002-6478-6789
date: "`r Sys.Date()`"
output: distill::distill_article
bibliography: literature.bib
preview: distill-preview.png
draft: true
---
The quality of document type classification in scholarly databases can vary when analysing bibliometric data. It can happen that a publication can be assigned to different document types in different services or that the document type does not correspond to the actual document type at all. This is the case, for example, when a letter to the editor is labelled as a research article in a scientific journal. To shed more light on this problem, we submitted an [article](https://arxiv.org/abs/2406.15154) in June 2024 that analyses the differences in the classification of document and publication types in the bibliometric databases OpenAlex, Web of Science, Scopus, PubMed and Semantic Scholar. 

Based on the results of this analysis, I developed a classifier that helps to reduce the proportion of incorrectly classified research items in OpenAlex. The classifier uses metadata from OpenAlex, such as the number of references, citations and affiliations, to assess whether an item in a scientific journal is a research contribution or not. 

## Data and Methods
The document type classifier was trained on about 9.5 million journal items from PubMed, for which each document type was reclassified as either research discourse or editorial discourse. Training data was restricted to the publication years 2012 to 2022. Additional metadata was retrieved from CrossRef and OpenAlex and supplemented. These are:

| Metadata                 | Type    |
| -------------------------| --------|
| has abstract?            | BOOLEAN |
| title word count         | INT     |
| page length              | INT     |
| author count             | INT     |
| has license?             | BOOLEAN |
| number of citations      | INT     |
| number of references     | INT     |
| has funding information? | BOOLEAN |
| number of affiliations   | INT     |
| has OA url?              | BOOLEAN |

The dataset was then split into 75% training data and 25% test data. After experimenting with several machine learning algorithms, I decided to forego with the [k-nearest neighbours algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm). Parameters for the algorithm were optimised using [grid search](https://en.wikipedia.org/wiki/Hyperparameter_optimization). If you want to have a look at the exact parameters that were used for the algorithm and also the programming code, you can visit my [project repo on GitHub](https://github.com/naustica/openalex_doctypes/tree/classifier/classifier).

To evaluate the classification model, I will compare the results of my classifier with OpenAlex, the [CWTS Open Leiden Ranking](https://open.leidenranking.com) and Scopus. 

## Results
Figure \@ref(fig:cwts) compares the results of my classifier with OpenAlex and CWTS, based on items in scientific journals between 2012 and 2021. The grey line shows all articles and reviews in journals in OpenAlex. The green line shows all articles and reviews in OpenAlex for which at least one reference and one citation was found in OpenAlex. The purple line below shows all items from journals in OpenAlex that are included as core publications in the CWTS Open Leiden Ranking. The pink line shows the proportion of items in OpenAlex that are recognised as research items by my classifier. 

As you can see, 

```{r cwts, echo=FALSE, layout='l-body-outset', fig.cap='Comparison CWTS'}
knitr::include_graphics('./media/oal_cwts_comparison.png', dpi=NA)
```

Figure \@ref(fig:scp) compares the proportion of articles and reviews in OpenAlex and Scopus in relation to the intersection of items in OpenAlex and Scopus in journals from 2012 to 2021. The results of my classifier are represented by the pink line. You can see that OpenAlex counts more items than Scopus when restricting to the document types articles and reviews. With the help of the classifier, the number of items classified as articles and reviews in OpenAlex decreases. Nevertheless, the count of articles and reviews in Scopus is still lower when comparing it to my method which may indicate that Scopus has a more sophisticated approach for classifying items. 

```{r scp, echo=FALSE, layout='l-body-outset', fig.cap='Comparison Scopus'}
knitr::include_graphics('./media/oal_scp_comparison.png', dpi=NA)
```

## Discussion and Outlook
The comparison of my classifier with OpenAlex, Scopus and the CWTS has shown that my classifier can certainly help to reduce the proportion of incorrectly classified items in OpenAlex. Nevertheless, a larger sample should be qualitatively analysed and contrasted for further evaluation. Meanwhile, OurResearch has begun to update its classification of document types, which may improve the bibliometric data in OpenAlex. Until then my classifier can be used as an optimisation of the existing document type classification. 
A major disadvantage of my classifier is that it often recognises clinical studies and case studies as non-research articles, as these often have no references or citations. However, this could be counteracted by adding open data from PubMed that classifies these document types. 
