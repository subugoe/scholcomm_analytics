---
title: "Identifying journal article types in OpenAlex"
description: Identifying suitable types of journal articles for bibliometric analyses is important. In this blog post, I present a document type classifier that helps to identify research contributions like original research articles using Crossref and OpenAlex. The classifier and classified OpenAlex records are openly available.
author:
  - name: Nick Haupka 
    affiliation: State and University Library Göttingen
    affiliation_url: https://www.sub.uni-goettingen.de/
    orcid_id: 0009-0002-6478-6789
date: "`r Sys.Date()`"
output: distill::distill_article
bibliography: literature.bib
preview: distill-preview.png
draft: true
---

Journals publish different types of articles. 
Original research articles and reviews are the most common and are most often used in bibliometric analyses. 
But there are also other types, such as letters to the editor or book reviews, which are often not considered.

Both the vocabulary used to describe journal article types and the methods used to assign them vary between bibliometric databases. 
For example, when [analysing the classification in OpenAlex, Web of Science (WoS), Scopus, PubMed and Semantic Scholar](https://arxiv.org/abs/2406.15154), I found that OpenAlex tends to overestimate the assignment of the document type 'article'. OpenAlex tagged 10% of items as articles, which were labelled as editorial material in Scopus and the Web of Science.

In this blog post, I will present a classifier designed to improve the identification of journal article types in open scholarly databases like OpenAlex. 
The classifier uses metadata from Crossref and OpenAlex, including the number of references, citations and affiliations, to assess whether an item in a journal is a research contribution or not. 
To train the classifier, I used open scholarly data from PubMed, OpenAlex and Crossref.
After introducing the classifier, I will compare my approach with that of OpenAlex, Scopus and  the methodology employed by the CWTS to identify core publications.
Both the source code of the classifier and the classified records are publicly accessible.

## Data and Methods

The journal article type classifier was trained on approximately 9.5 million journal articles from PubMed, representing either research discourse or editorial discourse.
PubMed was used because its classification of document types is similar to that of Scopus and Web of Science, with the advantage that PubMed data is openly accessible and reusable. 
The training data was limited to the publication years 2012 to 2022. 
In addition, articles from publishers with fewer than 5,000 publications were excluded from the training. 
Similar to the CWTS approach to identify core publications, the classifier also takes into account metadata retrieved from Crossref and OpenAlex.
These metadata fields are:

| Metadata                 | Type    | Retrieved from                   | 
| -------------------------| --------|----------------------------------|
| has abstract?            | BOOLEAN | Crossref (October 2023 snapshot) |
| title word count         | INT     | Crossref (October 2023 snapshot) |
| page count               | INT     | Crossref (October 2023 snapshot) |
| author count             | INT     | Crossref (October 2023 snapshot) |
| has license?             | BOOLEAN | Crossref (October 2023 snapshot) |
| number of citations      | INT     | Crossref (October 2023 snapshot) |
| number of references     | INT     | Crossref (October 2023 snapshot) |
| has funding information? | BOOLEAN | Crossref (October 2023 snapshot) |
| number of affiliations   | INT     | OpenAlex (April 2024 snapshot)   |
| has OA url?              | BOOLEAN | OpenAlex (April 2024 snapshot)   |


The dataset was then split into 75% training data and 25% test data. 
For the classifier, I used the k-nearest neighbours algorithm.
Parameters for the algorithm were optimised using grid search. 

<aside>The exact parameters that were used for the algorithm and also the programming code are available on [GitHub](https://github.com/naustica/openalex_doctypes/tree/classifier/classifier). </aside>

The classifier is build on top of OpenAlex rule-based paratext recognition, which uses [title heuristics](https://github.com/ourresearch/openalex-guts/blob/main/detective/work_type_detective.py). 
This means that my classifier cannot classify pre-labelled editorial material from OpenAlex as research items. 

To evaluate my model, I compared the results with OpenAlex, Scopus and the [CWTS Leiden Ranking Open Edition](https://open.leidenranking.com). 
The CWTS Leiden Ranking Open Edition is a university ranking based on a pre-computed subset of so called core publications indexed in OpenAlex to compare universities. 
A publication is considered a core publication if it has one or more authors, has at least one reference, is published in English and is also published in a core journal. [ref]
A journal is considered a core journal if it has an international scope and also contains a high number of references. The CWTS approach is therefore more selective than my approach, because I did not exclude journals and non-English contributions.

For the comparison I used the August and September 2024 snapshot from OpenAlex [häh, warum zwei verschiedene Versionen], the July 2024 snapshot from Scopus and the data underlying the Leiden Ranking Open Edition 2024, which is available through Google BigQuery. Matching were carried out by DOI. 
 
## Results

[hier bitte mit absoluten zahlen beginnen]
Overall, my classifier identifies 11.6% of journal items classified as articles and reviews in OpenAlex as non-research items.
When restricting to the period 2012 to 2021, this figure drops to 9.9%, which can be explained by a lack of metadata for journal articles published before 2012.

Figure \@ref(fig:cwts) compares the results of my classifier with OpenAlex and the CWTS, based on items in scientific journals between 2012 and 2021. The grey line shows all articles and reviews in journals in OpenAlex. The green line shows all articles and reviews in OpenAlex for which at least one reference and one citation was found in OpenAlex. The purple line below shows all items from journals in OpenAlex that are included as core publications in the CWTS Leiden Ranking Open Edition. The yellow line shows the proportion of items in OpenAlex that are recognised as research items by my classifier. 

About 48.3% of all journal items in OpenAlex from 2012 to 2021 were categorised as core publications by the CWTS. This number is probably due to missing authors, affiliations and references (see also [here](https://zenodo.org/records/13879947))[Bitte BibTex verwenden, und viel früher zitieren; Der Hauptgrund liegt an der Exklusion von Journalen, es wäre gut, dass auch zu quantifizieren]. In contrast, my classifier identifies about 84,5% of journal items as research items which may demonstrate that the classifier is less sensitive to missing metadata [Hast du die gleiche Journalmenge genutzt, wenn ja, dann musst du das schreiben]. This observation can be also made when comparing the green and yellow lines. However, it should be noted that the CWTS classification and my classifier have a different application purpose. [Inwiefern?]

```{r cwts, echo=FALSE, layout='l-body-outset', fig.cap='Comparison of my classifier with OpenAlex and the CWTS core classification.'}
knitr::include_graphics('./media/oal_cwts_comparison.png', dpi=NA)
```


Figure \@ref(fig:scp) compares the proportion of articles and reviews in OpenAlex and Scopus in relation to the intersection of items in OpenAlex and Scopus in journals from 2012 to 2021 using a shared corpus based on DOI matching. The results of my classifier are represented by the yellow line. 
OpenAlex counts more items than Scopus when restricting to the document types articles and reviews (OpenAlex: 95.9% and Scopus: 87.6%). 
With the help of the classifier, the retrieval of articles and reviews in OpenAlex can be improved (Classifier: 93.2%). 
Nevertheless, Scopus counts were lower when comparing it to my method.

```{r scp, echo=FALSE, layout='l-body-outset', fig.cap='Comparison of my classifier with OpenAlex and Scopus.'}
knitr::include_graphics('./media/oal_scp_comparison.png', dpi=NA)
```

To check for potentially discriminatory behaviour of my classifier, I compared my approach with the CWTS approach by journal subject (see Figure \@ref(fig:topics)). Again, a common corpus based on DOI matching is used.
The figure shows that my classifier treats publications from different disciplines in a more balanced way, while the CWTS method excludes publications from the social sciences and humanities more often. 
This could be due to its language restriction to English to identify suitable publications. Moreover, [the CWTS] (https://www.leidenranking.com/information/indicators) points out that many social science journals were not considered as core journals due to the lack of a suitable number of references.

```{r topics, echo=FALSE, layout='l-page', fig.cap='Comparison of the coverage of my classifier with the CWTS core classification using topics from OpenAlex.'}
knitr::include_graphics('./media/figure3.png', dpi=NA)
```

## Discussion and Data Access

The comparison of my classifier with OpenAlex, Scopus and the CWTS has shown that it can help with document type assignments in open scholarly data sources such as Crossref and OpenAlex. My next step is to qualitatively check a larger sample. Meanwhile, OurResearch is also in the process of updating its classification of document types. Until then, my classifier can be used as a complementary tool for identifying suitable articles for bibliometric analysis using open scholarly data sources such as Crossref or OpenAlex.

A major limitation of my classifier is that it often identifies clinical trials and case studies as non-research articles, as these often have no references or citations. However, this could be improved by adding open data from PubMed that classifies these document types. 

The classified data is available via the publicly available [Google BigQuery instance provided by the SUB Göttingen](https://console.cloud.google.com/bigquery?ws=!1m4!1m3!3m2!1ssubugoe-collaborative!2sresources). Here you can also compare it with OpenAlex, Crossref and Semantic Scholar. To query it, you can use

```{sql query, eval=FALSE}
SELECT COUNT(DISTINCT(oal.doi)) AS n, type, label
FROM 'subugoe-collaborative.openalex.works' AS oal
JOIN 'subugoe-collaborative.resources.classification_article_reviews_september_2024' AS dt
   ON oal.doi = dt.doi
GROUP BY type, label
ORDER BY n DESC
```

The results will be constantly updated in line with the monthly release of OpenAlex and Crossref. I would be happy to get feedback about your experiences with the classifier! 